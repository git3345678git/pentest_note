# URLFinder


是一款


## 使用

```
Usage: URLFinder [-a user-agent] [-b baseurl] [-c cookie] [-d domainName] [-f urlFile] [-ff urlFile one]  [-h help]  [-i configFile]  [-m mode] [-max maximum] [-o outFile]  [-s Status] [-t thread] [-time timeout] [-u url] [-x proxy] [-z fuzz]

Options:
  -a string
        set user-agent
        设置user-agent请求头
  -b string
        set baseurl
        设置baseurl路径
  -c string
        set cookie
        设置cookie
  -d string
        set domainName
        指定获取的域名,支持正则表达式
  -f string
        set urlFile
        批量抓取url,指定文件路径
  -ff string
        set urlFile one
        与-f区别：全部抓取的数据,视为同一个url的结果来处理（只打印一份结果 | 只会输出一份结果）
  -h    this help
        帮助信息
  -i    set configFile
        加载yaml配置文件（不存在时,会在当前目录创建一个默认yaml配置文件）
  -m int
        set mode
        抓取模式 
           1 normal
             正常抓取（默认） 
           2 thorough
             深入抓取（默认url深入一层,js深入三层,-i可以自定义） 
           3 security
             安全深入抓取（过滤delete,remove等敏感路由.-i可自定义）  (default 1)
  -max int
        set maximum
        最大抓取链接数 (default 99999)
  -o string
        set outFile
        结果导出到csv、json、html文件,需指定导出文件目录,可填写完整文件名只导出一种类型（.代表当前目录）
  -s string
        set Status
        显示指定状态码,all为显示全部（多个状态码用,隔开）
  -t int
        set Thread
        设置线程数（默认50） (default 50)
  -time int
        set Timeout
        设置超时时间（默认5,单位秒） (default 5)
  -u string
        set Url
        目标URL
  -x string
        set Proxy
        设置代理,格式: http://username:password@127.0.0.1:8809
  -z int
        set Fuzz
        对404链接进行fuzz(只对主域名下的链接生效,需要与 -s 一起使用） 
           1 decreasing
             目录递减fuzz 
           2 2combination
             2级目录组合fuzz（适合少量链接使用） 
           3 3combination
             3级目录组合fuzz（适合少量链接使用） 

```


## 快速使用

单url
```
显示全部状态码
./URLFinder-u http://www.baidu.com -s all -m 3

显示200和403状态码
./URLFinder-u http://www.baidu.com -s 200,403 -m 3
```


批量url
```
结果分开保存
导出全部
./URLFinder-s all -m 3 -f url.txt -o .

只导出html
./URLFinder-s all -m 3 -f url.txt -o res.html

结果统一保存
./URLFinder-s all -m 3 -ff url.txt -o .
```


高級
```
# 找當前頁面，所有URL
./URLFinder -u http://dvwa.com    -m 1   -c 'PHPSESSID=uabft2ttb49q4pnfp79soehgdr; security=impossible 123'


# 找當前頁面，所有有關於 dvwa.com 的 URL
./URLFinder -u http://dvwa.com  -d dvwa.com  -m 1   -c 'PHPSESSID=uabft2ttb49q4pnfp79soehgdr; security=impossible 123'



#在dvwa.com 下尋找有關於github.com
./URLFinder -u http://dvwa.com -s all  -d github.com -m 1  -c 'PHPSESSID=25s7a8eb0nv211umj84t7nt52r; expires=Tue, 09 Apr 2024 14:01:33 GMT; Max-Age=86400; path=/'



# 使用proxy搭配 burpsuite 的爬蟲可以找到很多
# 注意搭配 BP 可能會使bp的sitemap 出現不正確混亂或重複，但好處是可以發現很多東西。甚至是主機絕對路徑。
# 建議開兩個session 做對比 一個乾淨的 一個是使用URLFinder卦proxy跑的


./URLFinder -u http://dvwa.com -s all  -d dvwa.com -m 1   -c 'PHPSESSID=25s7a8eb0nv211umj84t7nt52r; expires=Tue, 09 Apr 2024 14:01:33 GMT; Max-Age=86400; path=/' -x http://127.0.0.1:8080



# 輸出 -o . 當前目錄，會產生3種檔案， csv html json 很棒。
./URLFinder -u http://dvwa.com    -m 2  -d dvwa.com -c '__gsas=ID=1d6e030ba05f153b:T=1710312116:RT=1710312116:S=ALNI_MZY7WY32GAeWiyiTM6PbtwAEGGG0w; security=low 123; PHPSESSID=oetemhdc51je4mtqprpsh656ie' -o .        




```


## 經驗1
他會把所有長得像路徑的都加入目標，並測試，所以有些404，並一定是真的存在路徑

```
<style type="text/css"></style>
<script type="text/javascript"></script>

http://dvwa.com/text/javascript                                     [ Status: 404, Size: 270, Title: 404 Not Found, Source: http://dvwa.com ]                                                                                                
http://dvwa.com/text/css                                            [ Status: 404, Size: 270, Title: 404 Not Found, Source: http://dvwa.com ]       
```


## 經驗2
比較麻煩的是，這類的工具會真實發出請求，假設不小心請求到，logout.php 那就真的會登出。
所以每個cookie 只能使用一次。，除非這工具有添加黑名單，但應該沒有
```
#會登出，所以只能使用一次
./URLFinder -u http://dvwa.com -s all   -m 1  -d dvwa.com -c 'PHPSESSID=uabft2ttb49q4pnfp79soehgdr; security=impossible'



# 我找到dvwa登出的漏洞
# cookie中的 security 後面隨便加一些字串，他就沒有註銷 session。(一般是logout.php 就註銷 session)
./URLFinder -u http://dvwa.com -s all   -m 1  -d dvwa.com -c 'PHPSESSID=uabft2ttb49q4pnfp79soehgdr; security=impossible 123'


```

## 經驗3

單純當一層爬蟲 -m 1 然後如果不要驗證，不加-s 

```
./URLFinder -u http://dvwa.com    -m 1  -d dvwa.com -c '__gsas=ID=1d6e030ba05f153b:T=1710312116:RT=1710312116:S=ALNI_MZY7WY32GAeWiyiTM6PbtwAEGGG0w; security=low 123; PHPSESSID=oetemhdc51je4mtqprpsh656ie'

```