# waymore



usage:
```
usage: waymore [-h] [-i INPUT] [-n] [-mode {U,R,B}] [-oU OUTPUT_URLS] [-oR OUTPUT_RESPONSES] [-f] [-fc FC] [-mc MC]
               [-l <signed integer>] [-from <yyyyMMddhhmmss>] [-to <yyyyMMddhhmmss>] [-ci {h,d,m,none}]
               [-ra REGEX_AFTER] [-url-filename] [-xwm] [-xcc] [-xav] [-xus] [-xvt] [-lcc LCC] [-lcy LCY]
               [-t <seconds>] [-p <integer>] [-r RETRIES] [-m <integer>] [-ko [KEYWORDS_ONLY]] [-lr LIMIT_REQUESTS]
               [-ow] [-nlf] [-c CONFIG] [-wrlr WAYBACK_RATE_LIMIT_RETRY] [-urlr URLSCAN_RATE_LIMIT_RETRY] [-co]
               [-nd] [-oijs] [-v] [--version]

waymore - by @Xnl-h4ck3r: Find way more from the Wayback Machine

options:
  -h, --help            show this help message and exit
  -i INPUT, --input INPUT
                        The target domain (or file of domains) to find links for. This can be a domain only, or a
                        domain with a specific path. If it is a domain only to get everything for that domain,
                        don't prefix with "www."
  -n, --no-subs         Don't include subdomains of the target domain (only used if input is not a domain with a
                        specific path).
  -mode {U,R,B}         The mode to run: U (retrieve URLs only), R (download Responses only) or B (Both).
  -oU OUTPUT_URLS, --output-urls OUTPUT_URLS
                        The file to save the Links output to, including path if necessary. If the "-oR" argument is
                        not passed, a "results" directory will be created in the path specified by the
                        DEFAULT_OUTPUT_DIR key in config.yml file (typically defaults to "~/.config/waymore/").
                        Within that, a directory will be created with target domain (or domain with path) passed
                        with "-i" (or for each line of a file passed with "-i").
  -oR OUTPUT_RESPONSES, --output-responses OUTPUT_RESPONSES
                        The directory to save the response output files to, including path if necessary. If the
                        argument is not passed, a "results" directory will be created in the path specified by the
                        DEFAULT_OUTPUT_DIR key in config.yml file (typically defaults to "~/.config/waymore/").
                        Within that, a directory will be created with target domain (or domain with path) passed
                        with "-i" (or for each line of a file passed with "-i").
  -f, --filter-responses-only
                        The initial links from Wayback Machine will not be filtered (MIME Type and Response Code),
                        only the responses that are downloaded, e.g. it maybe useful to still see all available
                        paths from the links even if you don't want to check the content.
  -fc FC                Filter HTTP status codes for retrieved URLs and responses. Comma separated list of codes
                        (default: the FILTER_CODE values from config.yml). Passing this argument will override the
                        value from config.yml
  -mc MC                Only Match HTTP status codes for retrieved URLs and responses. Comma separated list of
                        codes. Passing this argument overrides the config FILTER_CODE and -fc.
  -l <signed integer>, --limit <signed integer>
                        How many responses will be saved (if -mode is R or B). A positive value will get the first
                        N results, a negative value will will get the last N results. A value of 0 will get ALL
                        responses (default: 5000)
  -from <yyyyMMddhhmmss>, --from-date <yyyyMMddhhmmss>
                        What date to get responses from. If not specified it will get from the earliest possible
                        results. A partial value can be passed, e.g. 2016, 201805, etc.
  -to <yyyyMMddhhmmss>, --to-date <yyyyMMddhhmmss>
                        What date to get responses to. If not specified it will get to the latest possible results.
                        A partial value can be passed, e.g. 2016, 201805, etc.
  -ci {h,d,m,none}, --capture-interval {h,d,m,none}
                        Filters the search on Wayback Machine (archive.org) to only get at most 1 capture per hour
                        (h), day (d) or month (m). This filter is used for responses only. The default is 'd' but
                        can also be set to 'none' to not filter anything and get all responses.
  -ra REGEX_AFTER, --regex-after REGEX_AFTER
                        RegEx for filtering purposes against links found all sources of URLs AND responses
                        downloaded. Only positive matches will be output.
  -url-filename         Set the file name of downloaded responses to the URL that generated the response, otherwise
                        it will be set to the hash value of the response. Using the hash value means multiple URLs
                        that generated the same response will only result in one file being saved for that
                        response.
  -xwm                  Exclude checks for links from Wayback Machine (archive.org)
  -xcc                  Exclude checks for links from commoncrawl.org
  -xav                  Exclude checks for links from alienvault.com
  -xus                  Exclude checks for links from urlscan.io
  -xvt                  Exclude checks for links from virustotal.com
  -lcc LCC              Limit the number of Common Crawl index collections searched, e.g. '-lcc 10' will just
                        search the latest 10 collections (default: 3). As of July 2023 there are currently 95
                        collections. Setting to 0 (default) will search ALL collections. If you don't want to
                        search Common Crawl at all, use the -xcc option.
  -lcy LCY              Limit the number of Common Crawl index collections searched by the year of the index data.
                        The earliest index has data from 2008. Setting to 0 (default) will search collections or
                        any year (but in conjuction with -lcc). For example, if you are only interested in data
                        from 2015 and after, pass -lcy 2015. If you don't want to search Common Crawl at all, use
                        the -xcc option.
  -t <seconds>, --timeout <seconds>
                        This is for archived responses only! How many seconds to wait for the server to send data
                        before giving up (default: 30 seconds)
  -p <integer>, --processes <integer>
                        Basic multithreading is done when getting requests for a file of URLs. This argument
                        determines the number of processes (threads) used (default: 1)
  -r RETRIES, --retries RETRIES
                        The number of retries for requests that get connection error or rate limited (default: 1).
  -m <integer>, --memory-threshold <integer>
                        The memory threshold percentage. If the machines memory goes above the threshold, the
                        program will be stopped and ended gracefully before running out of memory (default: 95)
  -ko [KEYWORDS_ONLY], --keywords-only [KEYWORDS_ONLY]
                        Only return links and responses that contain keywords that you are interested in. This can
                        reduce the time it takes to get results. If you provide the flag with no value, Keywords
                        are taken from the comma separated list in the "config.yml" file with the "FILTER_KEYWORDS"
                        key, otherwise you can pass an specific Regex value to use, e.g. -ko "admin" to only get
                        links containing the word admin, or -ko "\.js(\?|$)" to only get JS files. The Regex check
                        is NOT case sensitive.
  -lr LIMIT_REQUESTS, --limit-requests LIMIT_REQUESTS
                        Limit the number of requests that will be made when getting links from a source (this
                        doesn't apply to Common Crawl). Some targets can return a huge amount of requests needed
                        that are just not feasible to get, so this can be used to manage that situation. This
                        defaults to 0 (Zero) which means there is no limit.
  -ow, --output-overwrite
                        If the URL output file (default waymore.txt) already exists, it will be overwritten instead
                        of being appended to.
  -nlf, --new-links-file
                        If this argument is passed, a .new file will also be written that will contain links for
                        the latest run. This is only relevant for mode U.
  -c CONFIG, --config CONFIG
                        Path to the YML config file. If not passed, it looks for file 'config.yml' in the same
                        directory as runtime file 'waymore.py'.
  -wrlr WAYBACK_RATE_LIMIT_RETRY, --wayback-rate-limit-retry WAYBACK_RATE_LIMIT_RETRY
                        The number of minutes the user wants to wait for a rate limit pause on Watback Machine
                        (archive.org) instead of stopping with a 429 error (default: 3).
  -urlr URLSCAN_RATE_LIMIT_RETRY, --urlscan-rate-limit-retry URLSCAN_RATE_LIMIT_RETRY
                        The number of minutes the user wants to wait for a rate limit pause on URLScan.io instead
                        of stopping with a 429 error (default: 1).
  -co, --check-only     This will make a few minimal requests to show you how many requests, and roughly how long
                        it could take, to get URLs from the sources and downloaded responses from Wayback Machine.
  -nd, --notify-discord
                        Whether to send a notification to Discord when waymore completes. It requires
                        WEBHOOK_DISCORD to be provided in the config.yml file.
  -oijs, --output-inline-js
                        Whether to save combined inline javascript of all relevant files in the response directory
                        when "-mode R" (or "-mode B") has been used. The files are saved with the name
                        "combined_inline{}.js" where "{}" is the number of the file, saving 1000 unique scripts per
                        file.
  -v, --verbose         Verbose output
  --version             Show version number

```


### -f 選項，

- 因為我想waymore.txt包含所有可能的連結。儘管我不關心圖像、字體等，但查看所有可能的路徑和參數仍然很有用。不過，任何過濾器都將始終應用於下載存檔的回應。您不想浪費時間下載數千張圖片！



假设你使用 Wayback Machine 下载了一个网站的存档数据，该网站包含以下页面：

1. `/index.html` - 包含文本内容
2. `/images/logo.png` - 图片文件
3. `/about.html` - 包含文本内容

如果你使用了 `-f` 或 `--filter-responses-only` 选项，那么初始链接（上述的1、2、3）将不会被过滤。但是只有响应数据会被过滤。这意味着只有包含文本内容的页面（例如 `/index.html` 和 `/about.html`）会被检查，而图片文件 `/images/logo.png` 则不会被检查。

所以，即使你不想检查图片等非文本内容，你仍然可以看到所有可用的链接路径。



## 檔案預設輸出位置
```
~/.config/waymore/results/
```
可以添加 config.yml 到` ~/.config/waymore/` 修改自定義




## 基本使用
```
# -mode B 運行模式：（U僅檢索 URL）、R（僅下載回應）或B（兩者）
# 通常產生三類檔案
# 1.index.txt   告訴你抓取什麼頁面，讓你方便查閱，並產生 hash 檔名，好處是相同response hash值一樣，# 所以不會生成重複檔案
# 2.waymore.txt 就跟 wayback 上點擊url 一樣，wayback上所有收錄 xcy.plus 的URL
# 3.很多hash.html or hash.txt (通常是robots.txt的hash) 
# -xcc, -xav, -xus, -xvt: 
# 這些選項用於排除特定來源的連結檢查，分別排除了commoncrawl.org、alienvault.com、urlscan.io和virustotal.com的連結檢查。

python waymore.py -i xcy.plus -mode B -f -xcc -xav -xus -xvt 


```




## 輸出JS
```
# -oijs 特別輸出JS 好用
#combinedInline{}.js 其中{}是文件編號，每個文件保存 1000 個唯一腳本 (內聯腳本)
#combinedInlineSrc.txt，其中包含src文件中引用的所有外部腳本的值。

python waymore.py -i xcy.plus -mode B -f -xcc -xav -xus -xvt  -oijs



# 會只抓跟 xcy.plus 有關的JS 但這樣會失去內聯腳本。
waymore.py -i xcy.plus -mode B  -xcc -xav -xus -xvt  -ko "\.js(\?|$)"



python waymore.py -i xcy.plus -mode B -f -xcc -xav -xus -xvt  -oijs -from 202109 -to 202206
```


## 好用
```

-ci 設定為none不過濾任何內容並獲取所有回應。但上限 5000
python waymore.py -i xcy.plus -mode B -f -xcc -xav -xus -xvt  -ci none       

# 自訂增加數量 
python waymore.py -i sunboyshop.com -mode B -f -xcc -xav -xus -xvt  -l -20000   -ci none -oijs


# 自訂增加數量 配合 時間點
#  -l -20000 -from 2021 -to 2022 
python waymore.py -i xcy.plus -mode B -f -xcc -xav -xus -xvt  -l -20000 -from 2021 -to 2022  -ci none 



#在加上提取JS
python waymore.py -i xcy.plus -mode B -f -xcc -xav -xus -xvt  -l -20000 -from 2021 -to 2022  -ci none -oijs





# -ko 提取敏感信息，可自訂，沒有就依照yml檔
python waymore.py -i xcy.plus -mode B -f -xcc -xav -xus -xvt  -l -20000 -from 2021 -to 2022  -ci none -ko




```



## 跳轉(未完成)
有時舊站會跳到最新的站

有時舊站會跳舊站，所以多使用 -fc  預社文件config.yml
```
FILTER_CODE: 301,302,200
```


## 使用心得

這工具還有很多功能，設計也很靈活，跟 wayback_machine_downloader 比較應該是更快速定位，wayback_machine_downloader比較像是，全面搜索，並且會下載圖片跟其他檔案。
這工具可以自定義。推薦這款。

他的hash response 功能很棒，同一個頁面就歸類到一起，假設過去不同站長的hash是123，就可以快速知道123不是我們要尋找的。























